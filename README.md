# SAFE-T: Safety Algorithm Fairness Evaluation for Transportation

[![Deploy](https://img.shields.io/github/actions/workflow/status/safe-t-ai/safe-t-ai.github.io/deploy.yml?branch=main&label=deploy&logo=github&style=classic)](https://github.com/safe-t-ai/safe-t-ai.github.io/actions/workflows/deploy.yml)
[![Data Refresh](https://img.shields.io/github/actions/workflow/status/safe-t-ai/safe-t-ai.github.io/data-refresh.yml?branch=main&label=data&logo=github&style=classic)](https://github.com/safe-t-ai/safe-t-ai.github.io/actions/workflows/data-refresh.yml)
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC_BY_4.0-blue.svg?style=classic)](LICENSE)
[![Code: MIT](https://img.shields.io/badge/Code-MIT-blue.svg?style=classic)](LICENSE-CODE)
[![Python](https://img.shields.io/badge/python-3.9+-blue?logo=python&style=classic)](https://www.python.org/)
[![Node](https://img.shields.io/badge/node-18+-green?logo=node.js&style=classic)](https://nodejs.org/)

Auditing framework for evaluating equity and fairness in AI-driven transportation safety systems. Duke University.

**[Live Demo](https://safe-t-ai.github.io/)**

## Overview

AI-powered transportation tools increasingly drive safety budgets, crash predictions, and infrastructure priorities. This audit tests whether those tools treat Durham's communities equitably across four tests measuring how income and race correlate with AI accuracy, resource allocation, and demand visibility.

## Tests

### Volume Estimation

Evaluates whether AI volume estimation tools accurately predict pedestrian and cyclist volumes across all demographic groups.

**Finding:** Low-income areas undercounted by ~25%, high-income areas overcounted by ~8%, with high-minority areas showing 20% worse accuracy overall.

### Crash Prediction

Evaluates whether AI crash prediction models maintain consistent accuracy across income levels when forecasting safety outcomes.

**Finding:** AI prediction error significantly higher in low-income areas, with poorest quintile showing systematically worse model performance, leading to underallocation of safety resources.

### Infrastructure

Evaluates whether AI-driven infrastructure recommendation systems allocate safety budgets equitably.

**Finding:** AI allocation shows 29.5% disparate impact ratio (Q1 receives 29.5% as much per-capita as Q5), failing the 80% threshold. Need-based allocation achieves 83.8%, demonstrating feasible equity improvements.

### Suppressed Demand

Evaluates whether AI tools detect latent transportation demand in areas with poor infrastructure that suppresses observed usage.

**Finding:** Standard AI tools fail to detect suppressed demand, showing low correlation with potential need. Poor infrastructure in low-income areas masks actual demand, perpetuating underinvestment.

## Quick Start

```bash
# Install dependencies
make install

# Generate data and start dev server
make setup
make dev

# Open http://localhost:5173
```

## Architecture

- **Stack:** Python + GeoPandas + Vite + ECharts + Leaflet.js
- **Deployment:** Static site on GitHub Pages
- **Data Pipeline:** Automated via GitHub Actions

The data pipeline fetches Durham census data, simulates AI predictions with documented bias patterns, generates static JSON files, and automatically deploys.

## Project Structure

```
safe-t-ai.github.io/
├── backend/
│   ├── models/           # Analysis models (4 tests)
│   ├── tests/            # Pytest suite (48 tests, 70% coverage)
│   ├── utils/            # Demographic & geospatial analysis
│   └── config.py         # Centralized configuration
├── frontend/
│   ├── src/              # Test implementations + visualizations
│   └── public/           # Static site files
├── scripts/              # Data pipeline scripts
└── .github/workflows/    # CI/CD automation
```

## Data Sources

- **Census:** US Census Bureau ACS 5-Year Estimates
- **Boundaries:** TIGER/Line Shapefiles
- **Crash Data:** NCDOT non-motorist crashes via ArcGIS Feature Service
- **Infrastructure:** OpenStreetMap via Overpass API
- **AI Predictions:** Simulated with bias patterns from research literature

## Development

### Quality Checks

```bash
# Run tests with coverage (fails if <60%)
make test

# Run linting
make lint

# Auto-fix lint issues
make lint-fix

# Run all pre-commit hooks
make hooks
```

### Pre-commit Hooks

Hooks run automatically on `git commit`:
- Pytest with coverage enforcement
- ESLint
- Trailing whitespace removal
- YAML/JSON validation

Install: `make install-hooks` (included in `make setup`)

### CI/CD

```bash
# Trigger a data refresh (fetch APIs, run simulations, update data branch)
gh workflow run data-refresh.yml

# Trigger a deploy (build frontend with latest data, deploy to Pages)
gh workflow run deploy.yml
```

## Contributors

[Jonas Neves](https://www.linkedin.com/in/jonasnvs/) · [Lindsay Gross](https://www.linkedin.com/in/lindsay-gross1/) · [Shreya Mendi](https://www.linkedin.com/in/shreya-mendi/) · [Arnav Mahale](https://www.linkedin.com/in/arnavmahale/)

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md).

## License

[CC BY 4.0](LICENSE) for text and findings. [MIT](LICENSE-CODE) for code.
